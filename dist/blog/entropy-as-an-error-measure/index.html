
<!DOCTYPE html>
<html>
  <head>
    
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-112753095-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-112753095-1');
      </script>
    
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width" />
    <link rel="stylesheet" href="/style/semantic.min.css" type="text/css" media="all" />
    <link rel="stylesheet" href="/style/main.css" type="text/css" media="all" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism.min.css" integrity="sha256-N1K43s+8twRa+tzzoF3V8EgssdDiZ6kd9r8Rfgg8kZU=" crossorigin="anonymous" />
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.7.1/dist/katex.min.css">
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.7.1/dist/katex.min.js"></script>
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.7.1/dist/contrib/auto-render.min.js"></script>
      <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body);
        });
      </script>
    
    <script
      src="https://code.jquery.com/jquery-3.3.1.min.js"
      integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
      crossorigin="anonymous"></script>
    <script src="/style/semantic.min.js" charset="utf-8"></script>
    <script>
      function setIframeHeight(id) {
        var ifrm = document.getElementById(id);
        var doc = ifrm.contentDocument? ifrm.contentDocument:
            ifrm.contentWindow.document;
        ifrm.style.visibility = 'hidden';
        ifrm.style.height = "10px"; // reset to minimal height ...
        // IE opt. for bing/msn needs a bit added or scrollbar appears
        ifrm.style.height = window.getDocHeight( doc ) + 4 + "px";
        ifrm.style.visibility = 'visible';
      }


      function getDocHeight(doc) {
        doc = doc || document;
        // stackoverflow.com/questions/1145850/
        var body = doc.body, html = doc.documentElement;
        var height = Math.max( body.scrollHeight, body.offsetHeight,
            html.clientHeight, html.scrollHeight, html.offsetHeight );
        return height;
      }
    </script>
    <title>Entropy as an Error Measure</title>
  </head>
  <body class="Site">
    <div class="ui fixed navbar menu Site-header">
      <div class="ui container">
        <div class="ui left secondary menu">
          <a href="/" class="item">
            Siddharth
          </a>
        </div>
        <div class="ui right secondary menu">
          <a href="/blog" class="item">
            <i class="pencil icon"></i> Blog
          </a>
          <a href="/archive" class="item">
            <i class="archive icon"></i> Archive
          </a>
        </div>
      </div>
    </div>
    <div class="ui Site-content container">
      
<div>
  <h1 class="ui header">
    Entropy as an Error Measure
  </h1>
  <div class="ui divider"></div>
  <div>
    <p>In Shannon's paper <a href="http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf">A Mathematical Theory of Communication</a>, he represented a communication system using the following schematic:</p>
<img class="ui centered big image" src="/img/blog/schematic-comm-system.png">
<p>He defined <em>Entropy</em>, a quantity that forms the basis of information theory.</p>
<h2>Entropy</h2>
<p>Information Entropy is interpreted in many ways. One way that I like to think about it is in terms of <em>&quot; how much randomness is present in the state-space?&quot;</em> (Similar to <a href="https://www.wikiwand.com/en/Boltzmann%27s_entropy_formula">Boltzmann's Entropy</a>). It is defined as the following:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mo>=</mo><mo>−</mo><mi>K</mi><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></msubsup><msub><mi>p</mi><mi>i</mi></msub><mi>log</mi><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow></mrow><annotation encoding="application/x-tex">  H = -K \sum_{i = 1}^{n} p_i \log{p_i}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.6513970000000002em;"></span><span class="strut bottom" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.08125em;">H</span><span class="mrel">=</span><span class="mord">−</span><span class="mord mathit" style="margin-right:0.07153em;">K</span><span class="mop op-limits"><span class="vlist"><span style="top:1.1776689999999999em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span><span style="top:-0.000005000000000143778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span><span class="op-symbol large-op mop">∑</span></span></span><span style="top:-1.2500050000000003em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">n</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></span></p>
<p>where \(p_i\) is the probability of event <em>i</em>. (the constant K merely amounts to a choice of a unit of measure)</p>
<p>To get a feel for this, consider the following weather probabilities and their corresponding entropy:</p>
<pre class="language-python"><code class="language-python">H <span class="token operator">=</span> <span class="token keyword">lambda</span> xs<span class="token punctuation">:</span> <span class="token operator">-</span> numpy<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x <span class="token operator">*</span> numpy<span class="token punctuation">.</span>log2<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">if</span> x <span class="token operator">!=</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">,</span> xs<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token builtin">map</span><span class="token punctuation">(</span>H<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.25</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<table class="ui compact table"><thead>
<tr>
<th>Sunny</th>
<th>Rainy</th>
<th>Snowy</th>
<th>Foggy</th>
<th>Entropy</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
<td>2.0</td>
</tr>
<tr>
<td>0.5</td>
<td>0.2</td>
<td>0.2</td>
<td>0.1</td>
<td>1.76</td>
</tr>
<tr>
<td>0.8</td>
<td>0.1</td>
<td>0.05</td>
<td>0.05</td>
<td>1.02</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>As we can see, more uncertain our state-space is, the higher the entropy. If we know something for sure, there is no entropy. What's the use of this?</p>
<p>If you notice, we used a base of 2 for the logarithm. When the base is set to 2, we refer to the corresponding logarithm value as a <em>bit</em> (Shannon credits <a href="https://www.wikiwand.com/en/John_Tukey">J. W. Tukey</a> for this) Thus, the above Entropy can be roughly interpreted has <em>&quot;On avg, how many bits do we need to transmit information?&quot;</em> This turned out to be a super useful measure for building information systems (as shown in the above figure) that send information <em>efficiently</em>. Every time we had to send some information, we can encode them to bits, based on the probability of each event's occurrence. Maybe, more likely an event, lesser the bits we'd want to use for it.</p>
<p>Now we know how many bits we need (in principle) to transmit some information, but how do we measure our system's performance? Enter cross-entropy.</p>
<h3>Cross Entropy</h3>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mo>(</mo><mi>p</mi><mo separator="true">,</mo><mi>q</mi><mo>)</mo><mo>=</mo><mo>−</mo><mi>K</mi><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></msubsup><msub><mi>p</mi><mi>i</mi></msub><mi>log</mi><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow></mrow><annotation encoding="application/x-tex">  H(p, q) = -K \sum_{i = 1}^{n} p_i \log{q_i}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.6513970000000002em;"></span><span class="strut bottom" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathit">p</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord">−</span><span class="mord mathit" style="margin-right:0.07153em;">K</span><span class="mop op-limits"><span class="vlist"><span style="top:1.1776689999999999em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span><span style="top:-0.000005000000000143778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span><span class="op-symbol large-op mop">∑</span></span></span><span style="top:-1.2500050000000003em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">n</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord"><span class="mord mathit">p</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></span></p>
<p>Where \(q_i\) is our <em>predicted</em> probability of even <em>i</em> and \(p_i\) is the true probability of event <em>i</em>.</p>
<p>I think of Cross Entropy of as &quot;How well is our system doing?&quot;. i.e &quot;How many bits did we actually send?&quot; (not how many do we need)</p>
<p>What does it mean?</p>
<p>Staring at this formula, we can see that if \(q_i == p_i\), then cross-entropy is the same as entropy.</p>
<h3>Relative Entropy (or <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL Divergence</a>)</h3>
<p>The difference between Cross-Entropy and Entropy is called <em>Relative Entropy</em> or <em>KL Divergence</em>. It tells us &quot;How close our system is to the true entropy&quot;. Higher the Relative Entropy, lesser is our efficiency.</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo>(</mo><mi>p</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mo>)</mo><mo>=</mo><mi>H</mi><mo>(</mo><mi>p</mi><mo separator="true">,</mo><mi>q</mi><mo>)</mo><mo>−</mo><mi>H</mi><mo>(</mo><mi>p</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">  D_{KL}(p || q) = H(p, q) - H(p)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">D</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.07153em;">K</span><span class="mord mathit">L</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">p</span><span class="mord mathrm">∣</span><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathit">p</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathit">p</span><span class="mclose">)</span></span></span></span></span></p>
<p>Thus, higher the KL divergence, higher the bit wastage.</p>
<h2>Loss function using Cross Entropy</h2>
<p>Cross-Entropy is often used as an error measure for Classification models. <a href="https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy">Example</a></p>

  </div>
</div>


    </div>
    <footer class="ui Site-footer center aligned segment">
      <h2 class="ui header">
        <a href="https://twitter.com/_subsid"  class="item" target="_blank"><i class="icon twitter square"></i></a>
        <a href="https://www.linkedin.com/in/subsid"  class="item" target="_blank"><i class="linkedin icon"></i></a>
        <a href="https://www.github.com/subsid"  class="item" target="_blank"><i class="github icon"></i></a>
      </h2>
      <p style=>
        <a href="/blog" class="item">Blog</a>
        &nbsp;&#183;&nbsp;
        <a href="/archive" class="item">Archive</a>
        &nbsp;&#183;&nbsp;
        <a href="/feed.xml" class="item">RSS</a></p>
    </footer>
  </body>
</html>

