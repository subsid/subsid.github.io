[{"content":" When debugging, I often want to measure a piece of code\u0026#39;s performance/memory characteristics. I do this with the stdlib time class and psutil module.\nThese are some snippets I always have in my utils before starting a project.\nNote: I use perf_counter (i.e performance counter clock) to measure time. For more details, see this.\nMeasuring time and memory I use python\u0026#39;s contextmanager to manage state. Realpython has a nice post on this.\nUsing the context manager class import time import psutil class TimeMem(): def __init__(self, step_desc): self.step_desc = step_desc @staticmethod def mem_info(): \u0026#34;\u0026#34;\u0026#34; Returns process memory-usage in bytes \u0026#34;\u0026#34;\u0026#34; return psutil.Process(os.getpid()).memory_info().rss def delta(self): \u0026#34;\u0026#34;\u0026#34; Time taken in seconds \u0026#34;\u0026#34;\u0026#34; return time.perf_counter() - self.tic def mem_consumed(self, div=1): \u0026#34;\u0026#34;\u0026#34; Returns memory consumed when the context was active. Defaults to bytes. \u0026#34;\u0026#34;\u0026#34; return (self.mem_info() - self.mem_start) / div def __enter__(self): self.tic = time.perf_counter() self.mem_start = self.mem_info() logging.info(f\u0026#34;Start: {self.step_desc}\u0026#34;) def __exit__(self, exc_type, exc_value, exc_tb): logging.info(f\u0026#34;Done {self.step_desc} \u0026#34; f\u0026#34;Time {self.delta():.2f} seconds \u0026#34; f\u0026#34;Mem {self.mem_consumed(1024**2):.2f} MB\u0026#34;) Using the decorator syntax The context manager API can be verbose. Using the contextmanager decorator makes it more clear.\nfrom contextlib import contextmanager class Timer(): def __init__(self): self.tic = time.perf_counter() def delta(self): \u0026#34;\u0026#34;\u0026#34; Time taken in seconds \u0026#34;\u0026#34;\u0026#34; return time.perf_counter() - self.tic class Memory(): def __init__(self): self.initial = Memory.mem_info() @staticmethod def mem_info(): \u0026#34;\u0026#34;\u0026#34; Returns process memory-usage in bytes \u0026#34;\u0026#34;\u0026#34; return psutil.Process(os.getpid()).memory_info().rss def mem_consumed(self, div=1): \u0026#34;\u0026#34;\u0026#34; Returns memory consumed when the context was active. Defaults to bytes. \u0026#34;\u0026#34;\u0026#34; return (self.mem_info() - self.initial) / div @contextmanager def measure(step_name): t = Timer() m = Memory() try: logging.info(f\u0026#34;Start {step_name}\u0026#34;) yield finally: logging.info(f\u0026#34;Done {step_name} \u0026#34; f\u0026#34;Time {t.delta():.2f} seconds \u0026#34; f\u0026#34;Mem {m.mem_consumed(1024**2):.2f} MB\u0026#34;) import numpy with(TimeMem(\u0026#34;TimMem: Init numpy array\u0026#34;)): result = numpy.arange(10**9, dtype=numpy.int64) with(measure(\u0026#34;decorator: Init numpy array\u0026#34;)): result = numpy.arange(10**9, dtype=numpy.int64) ### 2023-03-11 13:43:44,567 root INFO Start: TimMem: Init numpy array 2023-03-11 13:43:45,541 root INFO Done TimMem: Init numpy array Time 0.97 seconds Mem 7629.34 MB 2023-03-11 13:43:45,542 root INFO Start decorator: Init numpy array 2023-03-11 13:43:46,523 root INFO Done decorator: Init numpy array Time 0.98 seconds Mem 7629.34 MB 2023 03 11 Measure Time and Memory With Contextlib Blog Snippets Python\n","permalink":"https://subsid.github.io/posts/2023-03-11-measure-time-and-memory-with-contextlib/","summary":"When debugging, I often want to measure a piece of code\u0026#39;s performance/memory characteristics. I do this with the stdlib time class and psutil module.\nThese are some snippets I always have in my utils before starting a project.\nNote: I use perf_counter (i.e performance counter clock) to measure time. For more details, see this.\nMeasuring time and memory I use python\u0026#39;s contextmanager to manage state. Realpython has a nice post on this.","title":"Python: Measure Time and Memory"},{"content":" Python does not come with reasonable logging defaults. The following code usually prints nothing.\nimport logging logging.info(\u0026#34;Hello world\u0026#34;) While it does provide `logging.basicConfig()` which kinda works (sets up stderr by default), I prefer setting this up myself.\nThis snippet sets up logging, adds a formatter and outputs error/info logs to the respective std streams.\nWithout setting up the filter for errors, log aggregators confuse a python error log with an info log. I\u0026#39;ve seen this in google stackdriver logs.\ndef remove_handlers(): logger = logging.getLogger() for h in list(logger.handlers): logger.removeHandler(h) def setup_logging(filename=None, level=\u0026#34;INFO\u0026#34;): ## Reset logger remove_handlers() logger = logging.getLogger() formatter = logging.Formatter(\u0026#34;%(asctime)s %(name)-12s %(levelname)-8s %(message)s\u0026#34;) consoleh = logging.StreamHandler(sys.stdout) nonerror = lambda record: record.levelno != logging.ERROR error = lambda record: record.levelno == logging.ERROR errorh = logging.StreamHandler(sys.stderr) errorh.setLevel(logging.ERROR) errorh.setFormatter(formatter) consoleh.setFormatter(formatter) consoleh.addFilter(nonerror) errorh.addFilter(error) logger.addHandler(consoleh) logger.addHandler(errorh) logger.setLevel(level) In notebooks/remote sessions, I prefer writing to files and not relying on the session.\nimport logging import sys def remove_handlers(): logger = logging.getLogger() for h in list(logger.handlers): logger.removeHandler(h) def file_logging(filename, level=\u0026#34;INFO\u0026#34;): ## Reset logger remove_handlers() logger = logging.getLogger() fh = logging.FileHandler(f\u0026#34;{filename}.log\u0026#34;) formatter = logging.Formatter(\u0026#34;%(asctime)s %(name)-12s %(levelname)-8s %(message)s\u0026#34;) fh.setFormatter(formatter) logger.addHandler(fh) logger.setLevel(level) logging.info(\u0026#34;Before setup\u0026#34;) setup_logging() logging.info(\u0026#34;Logs to stdout\u0026#34;) file_logging(\u0026#34;test_logs\u0026#34;) logging.info(\u0026#34;Logs to test_logs.log\u0026#34;) #### $ python test.py INFO:root:Logs to stdout 2023-03-11 13:06:39,551 root INFO Logs to stdout $ cat test_logs.log 2023-03-11 13:06:39,552 root INFO Logs to test_logs.log 2023 03 06 Python Logging Blog Snippets Python\n","permalink":"https://subsid.github.io/posts/2023-03-06-python-logging/","summary":"Python does not come with reasonable logging defaults. The following code usually prints nothing.\nimport logging logging.info(\u0026#34;Hello world\u0026#34;) While it does provide `logging.basicConfig()` which kinda works (sets up stderr by default), I prefer setting this up myself.\nThis snippet sets up logging, adds a formatter and outputs error/info logs to the respective std streams.\nWithout setting up the filter for errors, log aggregators confuse a python error log with an info log.","title":"Logging in Python"},{"content":" Sed stands for \u0026#34;Stream editor\u0026#34;. Here is a nice way to rename files with regex using sed. I was running a user study today, and mistyped the file prefix. This created 100s of files with the wrong name. My initial thought was to use a script to fix it, but then decided to lookup sed. Here is how I did it:\n$ touch fooops_1.txt fooops_2.txt fooops_3.txt $ ls Let\u0026#39;s say our goal was to type \u0026#34;foobar\u0026#34; as the prefix. Easy to rename with sed!\n$ ls | sed \u0026#39;s/foo\\(ops\\)\\(.*\\)/mv \u0026amp; foo_bar\\2/\u0026#39; mv fooops_1.txt foo_bar_1.txt mv fooops_2.txt foo_bar_2.txt mv fooops_3.txt foo_bar_3.txt The key with sed is, it streams its output to stdout. Hence we can pipe it to anything! Here, we make it output the linux move commmand and pipe it to sh to execute the command. Always good to verify command before executing it.\n$ ls | sed \u0026#39;s/foo\\(ops\\)\\(.*\\)/mv \u0026amp; foo_bar\\3/\u0026#39; | sh $ ls foo_bar_1.txt foo_bar_2.txt foo_bar_3.txt Blog:Sed to Rename files linux hacks Blog\n","permalink":"https://subsid.github.io/posts/2019-02-20-sed-rename/","summary":"Sed stands for \u0026#34;Stream editor\u0026#34;. Here is a nice way to rename files with regex using sed. I was running a user study today, and mistyped the file prefix. This created 100s of files with the wrong name. My initial thought was to use a script to fix it, but then decided to lookup sed. Here is how I did it:\n$ touch fooops_1.txt fooops_2.txt fooops_3.txt $ ls Let\u0026#39;s say our goal was to type \u0026#34;foobar\u0026#34; as the prefix.","title":"Sed to Rename files"},{"content":" Paper link\nThis paper talks about a static program analysis tool called Infer and its impact at facebook. Infer is based on a program analysis method called continuous reasoning.\nSummary This paper describes work in continuous reasoning, where formal reasoning about a (changing) codebase is done in a fashion which mirrors the iterative, continuous model of software development that is increasingly practiced in industry\nGiven the prevalence of CI/CD pipelines and code review processes, the author suggests that continuous reasoning will allow formal analysis to scale to large codebases if it is integrated into the programmer\u0026#39;s workflow. Infer is a static analysis tool for analyzing C, C++, Java, and Object-C code. Its written in OCaml. Since it runs on code diffs (rather than rebuilding the entire codebase), it is quite fast - order of low tens of minutes. This makes it a compelling tool for developers, as they get feedback during code reviews. (vs having a bug board for these errors)\nOne of the main reasons why Infer is fast is due to Automatic Composability.\nThe technical feature which enables Inferâ€™s diff-time deployment is compositionality. The idea of compositionality comes from language semantics: a semantics is compositional if the meaning of a complex phrase is defined in terms of the meanings of its parts and a means of combining them.\nThis idea is transferred to software analysis and is known as Compositional Analysis. By definition, compositional analysis does not rely on the whole program.\nCompositional Analysis: an automatic program analysis is compositional if the analysis result of a composite program is defined in terms of the analysis results of its parts and a means of combining them.\nWhy is it better to do this, as opposed to running a sophisticated verification tool independent of development?\nROFL ((Report Only Failure List)) Episode At Facebook, an earlier version of Infer was deployed as a batch process running once every night or so. The tool reported a bunch of errors and these were then manually assigned to appropriate developers. As it turned out, none of these issues were prioritized by the devs. This is because of 2 main reasons:\nMental effort of context switch It is hard for programmers to context switch to some old commit and work on it. Relevance Assigning an issue to the right person is a non-trivial task. Both of these reasons are addressed by a diff based analysis approach. The Infer engine acts as a bot reviewer that gives the developer meaningful comments during the review process. The Impact of this system was enormous at facebook - tens of thousands of bugs reported by Infer were fixed.\nA contrasting analysis tool, that relies on formal verification is s2n by Amazon. S2n does a full-fledged formal verification but does not scale to large codebases.\nReporting As mentioned before with ROFL, what and when to report is important. The following are some reporting possibilities:\nLean reporting of only new errors only on changed files is Inferâ€™s default at diff time. It is a low friction deployment: it avoids reporting pre-existing issues to an author of a diff, which typically will not be relevant to the diff. It supports the first axiom of industrial static analysis: Donâ€™t spam the developer. Bulky reporting can, when run on a large legacy codebase, result in numerous pre-existing issues being reported. Sometimes these can be overwhelming, and irrelevant to the diff author, so care is needed in this reporting mode. (With Infer, we are experimenting with it for certain bug types and certain projects.) Cautious reporting fits well with periodic global analyzer runs on an entire codebase, as opposed to at diff time. It has been used by Coverity, and versions of it are used for both static and dynamic analysis at Facebook. Clean is used for deployments that seek to keep a codebase entirely free of certain issues. The Amazon s2n effort uses this deployment, Infer has used it with the source code of the Buck build system, and it is commonly used with type systems. Though automatic composability is hard, it may be worth spending time on improving continuous analysis, due to its scalability and impact.\nBlog:Continous Reasoning Blog Paper Review\n","permalink":"https://subsid.github.io/posts/2019-02-03-continuous-reasoning/","summary":"Paper link\nThis paper talks about a static program analysis tool called Infer and its impact at facebook. Infer is based on a program analysis method called continuous reasoning.\nSummary This paper describes work in continuous reasoning, where formal reasoning about a (changing) codebase is done in a fashion which mirrors the iterative, continuous model of software development that is increasingly practiced in industry\nGiven the prevalence of CI/CD pipelines and code review processes, the author suggests that continuous reasoning will allow formal analysis to scale to large codebases if it is integrated into the programmer\u0026#39;s workflow.","title":"Continuous Reasoning: Scaling the impact of formal methods"},{"content":" In Shannon\u0026#39;s paper A Mathematical Theory of Communication, he represented a communication system using the following schematic:\nHe defined Entropy, a quantity that forms the basis of information theory.\nEntropy Information Entropy is interpreted in many ways. One way that I like to think about it is in terms of \u0026#34; how much randomness is present in the state-space?\u0026#34; (Similar to Boltzmann\u0026#39;s Entropy). It is defined as the following:\n$$ H = -K \\sum_{i = 1}^{n} p_i \\log{p_i} $$\nwhere $p_i$ is the probability of event i. (the constant K merely amounts to a choice of a unit of measure)\nTo get a feel for this, consider the following weather probabilities and their corresponding entropy:\nimport numpy as np H = lambda xs: - numpy.sum(map(lambda x: x * numpy.log2(x) if x != 0 else 0, xs)) return list(map(H, [[0.25, 0.25, 0.25, 0.25], [0.5, 0.2, 0.2, 0.1], [0.8, 0.1, 0.05, 0.05], [1, 0, 0, 0]])) Sunny Rainy Snowy Foggy Entropy 0.25 0.25 0.25 0.25 2.0 0.5 0.2 0.2 0.1 1.76 0.8 0.1 0.05 0.05 1.02 1 0 0 0 0 As we can see, more uncertain our state-space is, the higher the entropy. If we know something for sure, there is no entropy. What\u0026#39;s the use of this?\nIf you notice, we used a base of 2 for the logarithm. When the base is set to 2, we refer to the corresponding logarithm value as a bit (Shannon credits [J. W. Tukey] for this) Thus, the above Entropy can be roughly interpreted as\nOn avg, how many bits do we need to transmit information?\nThis turned out to be a useful measure for building information systems (as shown in the above figure) that send information efficiently. Every time we had to send some information, we can encode them to bits, based on the probability of each event\u0026#39;s occurrence. Maybe, more likely an event, lesser the bits we\u0026#39;d want to use for it.\nNow we know how many bits we need (in principle) to transmit some information, but how do we measure our system\u0026#39;s performance? Enter cross-entropy.\nCross Entropy $$ H(p, q) = -K \\sum_{i = 1}^{n} p_i \\log{q_i} $$\nWhere $q_i$ is our predicted probability of even $i$ and $p_i$ is the true probability of event $i$.\nI think of Cross Entropy of as \u0026#34;How well is our system doing?\u0026#34;. i.e \u0026#34;How many bits did we actually send?\u0026#34; (not how many do we need)\nWhat does it mean?\nStaring at this formula, we can see that if $q_i == p_i$, then cross-entropy is the same as entropy.\nRelative Entropy (or KL Divergence) The difference between Cross-Entropy and Entropy is called Relative Entropy or KL Divergence. It tells us \u0026#34;How close our system is to the true entropy\u0026#34;. Higher the Relative Entropy, lesser is our efficiency.\n$$ D_{KL}(p || q) = H(p, q) - H(p) $$\nThus, higher the KL divergence, higher the bit wastage.\nLoss function using Cross Entropy Cross-Entropy is often used as an error measure for Classification models. Example\nBlog:Entropy as an Error Measure Blog Machine Learning\n","permalink":"https://subsid.github.io/posts/2019-01-31-entropy-as-an-error-measure/","summary":"In Shannon\u0026#39;s paper A Mathematical Theory of Communication, he represented a communication system using the following schematic:\nHe defined Entropy, a quantity that forms the basis of information theory.\nEntropy Information Entropy is interpreted in many ways. One way that I like to think about it is in terms of \u0026#34; how much randomness is present in the state-space?\u0026#34; (Similar to Boltzmann\u0026#39;s Entropy). It is defined as the following:","title":"Entropy as an Error Measure"},{"content":" Toward a Unified Ontology of Cloud Computing L. Youseff, M. Butrico, and D. Da Silva, 2008 Grid Computing Environments Workshop, Austin, TX, 2008, pp. 1-10.\nThis paper is one of the early (relatively) works that summarizes the various components of Cloud Computing. At the time (2008), AWS was in the market only for a couple of years and Google cloud was just getting started. Thinking back, the classification described here is pretty much how most offerings these days are grouped.\nCloud Computing is one contemporary technology in which the research community has recently embarked. Manifesting itself as the descendant of several other computing research areas such as Service-Oriented Architecture, distributed and grid computing, and virtualization, cloud computing inherits their advancements and limitations.\nThe authors keep composability and layering as the central theme to their classification. i.e. Larger components are made from smaller components taken from SOA and each layer is built from lower layer components.\nCloud Application Layer is the most visible layer to the end users of a cloud service. Applications here are referred to as Software as a service, something we take for granted these days. Its probably what has led to the software startup boom. The ease of getting an application to production, with minimal maintenance, installation and other issues faced by on-prem deployments.\nDespite all the advantageous benefits of this model, several deployment issues hinder its wide adoption. Specifically, the security and availability of cloud applications are two of the major issues in this model, and they are currently avoided by the use of lenient service level agreements (SLA)\nWe\u0026#39;ve definitely come a long way in handling this problem over the last 10 years, with better monitoring (Prometheus, Datadog, deployment Docker, K8s, CI/CD pipelines (Jenkins, Teamcity, Travis).\nCloud Software Infrastructure layer is what is commonly referred to as PaaS. This covers the various tools for application developers, that are used to build the SaaS application. AWS-CLI in one example. This layer is where most abstractions are built for making it easier to get apps to production. Having an API for scaling, load-balancing, etc. Of course, the application developer can always bypass this layer if they want more pain :)\nCloud Software Infrastructure Layer can be divided into three parts:\nComputational Resources (dubbed Infrastructure as a service) Virtualization is the prime enabler for cloud infrastructure. It is what allows the provider to make money - Timesharing limited hardware for multiple users. Amazon\u0026#39;s EC2 is a good example of such a resource.\nThis was specifically enabled by two virtualization technologies: paravirtualization and hardware-assisted virtualization. Although both virtualization technologies have addressed performance isolation between virtual machines contending on common resources, performance interference between VMs sharing the same cache and TLB hierarchy cannot yet be avoided [12]. Further, the emergence of multicore machines into mainstream servers exacerbate this performance interference problem. In turn, the lack of strict performance isolation between VMs sharing the same physical node has resulted in the inability of cloud providers to give strong guarantees for performance to their clients. Instead, they offer them unsatisfactory SLAs in order to provide competitive pricing for the service. Such weak guarantees, unfortunately, can inject themselves up the layers of the cloud stack, and affect the SLAs of the cloud systems built above the IaaSâ€™s SLAs.\nData Storage Storage services such as S3, RDS, etc. Communication\nThis is an interesting component, where a lot of work has gone in recently. But I think most of the work in this area has come through applications that are deployed by the developer. (Such as Kafka, Apache Flink, etc.) While there are services such as Kinesis, SNS by AWS that do some of this, I think there is scope to provide services that are application independent in this layer.\nConsequently, cloud systems are obliged to provide some communication capability that is service oriented, configurable, schedulable, predictable, and reliable. Towards this goal, the concept of Communication as a Service (CaaS) emerged to support such requirements, as well as network security, dynamic provisioning of virtual overlays for traffic isolation or dedicated bandwidth, guaranteed message delay, communication encryption, and network monitoring.\nThe authors also mention Software Kernel and Hardware/Firmware as the two lowest layers, but these are mostly managed by the cloud provider, rather than the consumer.\nThe origins of modern cloud computing are often forgottenâ€¦\nHuge coperation, like Amazon and Google generally build their computing infrastructure to support the peak demand of their business. As the average demand of the system is however, several times smaller than the peak demand [18], their computing infrastructure is usually under-utilized and the cost of its operation constitutes an additional expense. In order to offset this extra expense, they have offered utilizing this surplus computing power as a service when it is not used by their business systems. Their offerings came at very attractive prices since they have deployed their systems at a large scale, and thus benefit from the economy-of-scale.\nAs mentioned by the authors, the biggest challenges in cloud computing are security and monitoring of large distributed services. (Still the case 10 years hence)\nBlog:Ontology of Cloud Computing Paper Review Blog ","permalink":"https://subsid.github.io/posts/2019-01-23-ontology-of-cloud-computing/","summary":"Toward a Unified Ontology of Cloud Computing L. Youseff, M. Butrico, and D. Da Silva, 2008 Grid Computing Environments Workshop, Austin, TX, 2008, pp. 1-10.\nThis paper is one of the early (relatively) works that summarizes the various components of Cloud Computing. At the time (2008), AWS was in the market only for a couple of years and Google cloud was just getting started. Thinking back, the classification described here is pretty much how most offerings these days are grouped.","title":"Toward a Unified Ontology of Cloud Computing"},{"content":" Smartereveryday video\nEntomology is study of insects. Phototaxis - movement of organism towards or away from light. +ve and -vely phototaxic based on towards or away from light.\nTheory 1 Moths and other bugs use heavenly bodies like the sun/moon to orient themselves while flying. They try to align themselves at a certain angle with the moon. But if the moon is brought superclose, the moth has to pitch up in order to maintain the angle, and this causes a logarithmic spiral into the source. People have tried to verify this, and its kinda true, but not always. hmmm Theory 2 This theory says that some species of moths align themselves straight towards a light source and fly towards it. (A light source is usually like an opening, making the insect fly towards it so that it can fly freely without any objects in between) Blog:Bugs Atrracted to Light Blog Science Fun Facts\n","permalink":"https://subsid.github.io/posts/2018-02-20-bugs-attracted-to-light/","summary":"Smartereveryday video\nEntomology is study of insects. Phototaxis - movement of organism towards or away from light. +ve and -vely phototaxic based on towards or away from light.\nTheory 1 Moths and other bugs use heavenly bodies like the sun/moon to orient themselves while flying. They try to align themselves at a certain angle with the moon. But if the moon is brought superclose, the moth has to pitch up in order to maintain the angle, and this causes a logarithmic spiral into the source.","title":"Why are bugs attracted to light"},{"content":" What is the difference between the following 2 code blocks, even though they produce the same output? If you are not sure, this post will help you.\nrm(list=ls()) x \u0026lt;- 1:1e8 g \u0026lt;- function(a){ b \u0026lt;- substitute(a) print(eval(b)) print(eval(b)) } g(mean(x)) [1] 5e+07 [1] 5e+07 rm(list=ls()) x \u0026lt;- 1:1e8 g \u0026lt;- function(a){ b \u0026lt;- quote(a) print(eval(b)) print(eval(b)) } g(mean(x)) [1] 5e+07 [1] 5e+07 One of the really (really) cool features of R is the idea of Non Standard Evaluation.\nCapturing expressions with substitute. Function arguments in R are evaluated lazily. Hadley\u0026#39;s book explains this in the context of R, if you want to learn more about the advantages and the idea in general, I recommend these readings in haskellâ€‹ and clojure.\nIn R, function arguments are evaluated only if they\u0026#39;re used.\nf \u0026lt;- function(x) { 10 } f(stop(\u0026#34;This is an error!\u0026#34;)) ## [1] 10 At an implementation level, this means that the argument passed to f is not a value, it\u0026#39;s a special type of object called promise. The advantage of this, is that we have access, not only to the final value, but also to the expression that computes it.\nWe can capture this expression using the substitute command and then evaluate it with eval.\nf \u0026lt;- function(x) { print(x) print(substitute(x)) print(eval(substitute(x))) } f(10 * 5 + 2) ## [1] 52 ## 10 * 5 + 2 ## [1] 52 What about quote? Let\u0026#39;s see.\nf \u0026lt;- function(x) { print(x) print(quote(x)) print(eval(quote(x))) } f(10 * 5 + 2) [1] 52 x [1] 52 Interesting! In this case, we don\u0026#39;t see the expression 10 * 5 + 2, but we see the variable x. In other words, quote captures its input as is. In this case, it just captures the promise.\nHow is this useful? quote let\u0026#39;s us capture variables that are not bound to anything in the environment yet. We can capture it, and later evaluate it, when the environment has a value for it.\nf \u0026lt;- function(x) { print(x) a \u0026lt;- 10 b \u0026lt;- 20 print(eval(x)) } f(quote(a * b + 5)) a and b were not defined when the function was called, but using quote we can still call the function!\nSo how does this work in our initial example? Since, substitute captures the expression, it has to reevaluate it everytime its called, but in case of quote, it evaluates it only once! (As the promise gets resolved the first time its called, and then just gets looked up) We can easily see this with some profiling.\nrm(list=ls()) time \u0026lt;- function(expr) { start \u0026lt;- proc.time() expr print(proc.time() - start) } x \u0026lt;- 1:1e8 g \u0026lt;- function(a){ ## substitute print(\u0026#34;substitute\u0026#34;) time(print(eval(substitute(a)))) time(print(eval(substitute(a)))) print(\u0026#34;quote\u0026#34;) ## quote time(print(eval(quote(a)))) time(print(eval(quote(a)))) } g(mean(x)) [1] \u0026#34;substitute\u0026#34; [1] 5e+07 user system elapsed 0.094 0.000 0.094 [1] 5e+07 user system elapsed 0.092 0.000 0.091 [1] \u0026#34;quote\u0026#34; [1] 5e+07 user system elapsed 0.103 0.000 0.103 [1] 5e+07 user system elapsed 0 0 0 References Hadley\u0026#39;s Advanced R Stat Computing course by James Long Blog:R Quote vs Substitute Programming Languages Blog\n","permalink":"https://subsid.github.io/posts/2018-01-18-r-quote-vs-substitute/","summary":"What is the difference between the following 2 code blocks, even though they produce the same output? If you are not sure, this post will help you.\nrm(list=ls()) x \u0026lt;- 1:1e8 g \u0026lt;- function(a){ b \u0026lt;- substitute(a) print(eval(b)) print(eval(b)) } g(mean(x)) [1] 5e+07 [1] 5e+07 rm(list=ls()) x \u0026lt;- 1:1e8 g \u0026lt;- function(a){ b \u0026lt;- quote(a) print(eval(b)) print(eval(b)) } g(mean(x)) [1] 5e+07 [1] 5e+07 One of the really (really) cool features of R is the idea of Non Standard Evaluation.","title":"R: Quote vs Substitute"},{"content":" If you are in the field of software, you\u0026#39;ve probably wondered at some point: What are the coolest algorithms ever discovered?. As a fun task, I decided to try and understand SIAM\u0026#39;s top 10 algorithms of the 20th century.\nThe Fast Fourier Transform (FFT) algorithm is revolutionary. The applications of FFT touches nearly every area of engineering in some way. The Cooley-Tukey paper rediscovered (It was found in Gauss\u0026#39;s notes for calculations in astronomy! ðŸ¤·) and popularized FFT. It is one of the most widely cited papers in science and engineering!\nFFT is something I\u0026#39;ve used a lot, but didn\u0026#39;t quite understand fully. I always thought of it as something that makes the Fourier transform faster, in order to view time domain signals in their frequency domain. In reality, that is just one application of FFT. For me, the key view point was: FFT is all about making basic polynomial operations fast!.\nPolynomials A Polynomial is an expression of the form\n$$ A(x) = a_0 + a_1x + a_2x^2 + a_3x^3 + ... a_{n-1}ax^{n-1} $$\nwhere $a_i$ are Real numbered coefficients(typically) and $x$ is some variable. $A(x)$ is defined to have a degree of n-1 (Yup, one less than the number of terms!)\nRepresentation of Polynomials How can polynomials be represented in a computer?\nCoefficient Representation $$ (a_0, a_1, a_2 ... a_{n-1}) $$ Simple enough, its a vector or list of numbers! This representation is often very useful, as it can represent any kind of one-dimensional data. Sure, if we care about $x$, we can write a function $A(x)$ to take some variable $x$ and do something with $x$ and these coefficents. If not, we just keep it as a vector.\nPoint-Value Representation $$(x_0, y_0), (x_1, y_1), (x_2, y_2), ... (x_{n-1}, y_{n-1})$$ Since a polynomial $A(x)$ can be thought of as a function from $x$ to $y$, another way to represent a polynomial would be by pairs of (input, output) values. Wow! Are you saying we need to define $A(x)$ at all possible values of $x$? Nope, it turns out there is a fundamental property of polynomials that states that:\nGiven $n$ pairs $(x_0,y_0)(x_{n-1},y_{n-1}),...$ all the $x_i$\u0026#39;s distinct, there is a unique polynomialn p(x) of degree (at most) n such that $p(x_i) = y_i$ for $0 \\le i \\le (n-1)$./\nIn other words, a polynomial of degree $(n-1)$ is uniquely specified by giving $n$ point-value pairs. Intuitively, that makes sense. How many points do we need to represent a line (which can be represented as a polynomial of the form $y = ax + b$)? 2 points! What continuous curve can we draw through 3 points? parabola! A proof can be found here.\nWhat can we do with a Polynomial? Evaluation Given a polynomial $p$ and a number x, compute p(x).\nAddition Given two polynomials $p(x)$ and $q(x)$, find a polynomial $r = p + q$, such that $r(x) = p(x) + q(x)$ for all $x$. If $p$ and $q$ both have degree $n$, then the sum also has degree $n$.\nMultiplication Given two polynomials $p(x)$ and $q(x)$, find a polynomial $r = pq$, such that $r(x) = p(x).q(x)$ for all $x$. If $p$ and $q$ both have degree $n$, then the product has degree $2n$.\nComplexity of these operations Assuming the polynomials are represented using the coefficient representation:\nEvaluation: A simple for-loop can achieve this in O(n) arithmetic operations. (We can cut down the multiplications further using horner\u0026#39;s scheme.\nAddition: A simple for-loop can achieve this in O(n) arithmetic operations.\nMultiplication: Ha! this is more complicated and takes O($n^2$) arithmetic operations. (Sure, we can reduce the asymptotic runtime by using some fancy tricks, but the constants are still pretty large.)\nWhat if we change the representation to point-value?\nAddition: Simple! Given 2 polynomials, $(x_1, y_1), (x_2, y_2), . . . (x_{n-1}, y_{n-1})$ and $(x_1, z_1), (x_2, z_2), . . . (x_{n-1}, z_{n-1})$ we simply add the output values and get $(x_i, y_i + z_i)$. Thus, it requires $O(n)$ arithmetic operations.\nNote: Both polynomials need to be defined for the same n points, else we\u0026#39;ll have to do a little more work using Lagrange interpolation.\nMultiplication: Simple! Given, 2 polynomials $(x_1, y_1), (x_2, y_2), . . . (x_{n-1}, y_{n-1})$ and $(x_1, z_1), (x_2, z_2), . . . (x_{n-1}, z_{n-1})$ we simply multiply the output values and get $(x_i, y_i * z_i)$. Thus, it requires $O(n)$ arithmetic operations.\nNote: When we multiply 2 polynomials, we are going to get a polynomial of higher degree, so we\u0026#39;ll need more points to represent it. For example, multiplying 2 $(n-1)$ degree polynomials will result in a polynomial of degree (2n - 1). This can be handled by taking more samples of the 2 input polynomials before multiplication\nSummary So this is where we are:\nRepresentation Multiply Evaluate Sum Coefficient $O(n^2)$ $O(n)$ $O(n)$ Point-Value $O(n)$ $O(n^2)$ $O(n)$ Can we somehow convert between the representations efficiently so that we get the best of both? This is where the FFT comes in!\nConverting between representations For a polynomial $A(x) = a_0 + a_1x + ... a_{n-1}x^{n-1}$ of degree $(n-1)$, the conversion from coefficient representation to point-value representation at n distinct points $(x_0, x_1, ... x_n)$ can be done as follows:\n$$\n\\begin{bmatrix} y_0 \\\\ y_1 \\\\ .\\\\ .\\\\ .\\\\ y_{n-1} \\\\ \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; x_0 \u0026amp; x_0^2 \u0026amp; ... \u0026amp; x_0^{n-1} \\\\ 1 \u0026amp; x_1 \u0026amp; x_1^2 \u0026amp; ... \u0026amp; x_1^{n-1} \\\\ .\\\\ .\\\\ .\\\\ 1 \u0026amp; x_{n-1} \u0026amp; x_{n-1}^2 \u0026amp; ... \u0026amp; x_{n-1}^{n-1} \\\\ \\end{bmatrix} \\begin{bmatrix} a_0 \\\\ a_1 \\\\ .\\\\ .\\\\ .\\\\ a_{n-1} \\\\ \\end{bmatrix} $$\nwhere $\\vec{a}$ is a vector of coefficients and $\\vec{y}$ is a vector of output values. This is known as the Vandermonde matrix. It\u0026#39;s a nice way of vectorizing the conversion and make the runtime $O(n^2) operations$. Thus, if we need the $y_i$ values for point-value representation, we simply do $$\\vec{y} = V\\vec{a}$$\nTo convert from point-value to coefficient representation, we take the inverse of $V^{-1}$.\n$$V^{-1}\\vec{y} = \\vec{a}$$\nFact: $V$ is inverttible if $x_i$\u0026#39;s are distinct.\nAnyways, the point is, the forward and reverse conversion takes $O(n^2)$ operations.\nCan we do better? If you look at the above matrix-vector product hard enough, you\u0026#39;ll notice that we get to pick the x values in $V$. i.e The sample positions! If we pick these sample values with the \u0026#39;right structure\u0026#39;, maybe this conversion can be faster. Sure, it is not very generic, but we don\u0026#39;t care! We still get to convert between point-value $\\leftrightarrow$ coefficient representation of the given polynomial.\nFFT exploits this freedom\nDivide and Conquer! What is our goal? Before we lose the forest for the trees, this is what we want:\nWe have a polynomial $A(x)$ in its coefficient form $\u0026lt;a_0, a_1, . . . a_{n-1}\u0026gt;$ and a input set $X$. We need to compute $\u0026lt;y_0, y_1, . . . y_{n-1}$ from $A(x) \\forall x \\in X$. The reason we want to do this, is so that we can quickly switch from coefficient to polynomial representation. (And vice-versa, but we\u0026#39;ll leave that for now) The key insight from the previous section was that we are free to choose the input set $X$. Ok, now back to divide and conquer.\nThe essence of any divide and conquer algorithm strategy is as follows:\nDivide problem into smaller subproblems. Recursively solve (conquer) the subproblems. Combine solutions to the subproblem into one for the original problem. The above link gives some basic examples in this paradigm.\nDivide and Conquer idea for Polynomials Consider the polynomial $A(x) = a_0 + a_1x + a_2x^2 + . . . a_{7}x^{7}$.\nDivide Express $A(x)$ as a sum of its odd and even powers.\n$$ A_{even}(x) = a_0 + a_2x + a_4x^2 + a_6x^3 $$ $$ A_{odd}(x) = a_1 + a_3x + a_5x^2 + a_7x^3 $$\nConquer Recursively compute $A_{even}(z)$ and $A_{odd}(z)$ $\\forall z \\in \\{ x^2 | x \\in X \\}$\nCombine Combine them with $O(1)$ arithmetic operations (Specifically, 1 multiplication and 1 addition) to get $A(x)$!\n$ A(x) = A_{even}(x^2) + xA_{odd}(x^2) $\nBasecase: We stop recursing, when our polynomial just has 1 coefficient\nNote that we evaluate both $A_{even}$ and $A_{odd}$ at $x^2$ for the numbers to work out. That\u0026#39;s key.\nDo we have smaller a subproblems?\ni.e, is $A_{even}(z)$ and $A_{odd}(z)$ $\\forall z \\in \\{ x^2 | x \\in X \\}$ smaller than $A(x) \\forall x \\in X$?\nIf we look at the the set of input values on which $A_{even}$ and $A_{odd}$ are evaluated, we still need them to be defined for all values of $x^2$.\nFor the divide and conquer technique to work, we need the subproblems to be of a smaller size.\nCan we find a set of $n$ points such that the set formed by squaring each value, is a smaller set?\nIf my set $X = \\{x^2\\}$ with one element. What can my set \u0026#39;x\u0026#39; be, so that it is bigger?\nYup, it can be $X = \\{x, -x\\}$. Ha, squareroots can do the trick! Ok, this works if we only need 2 sample values in our set X, what if we need 3?\nHmm, that seems complex ;)\nEnter Complex Number! Restating our problem here, just so we don\u0026#39;t get lost:\nIn order to represent our polynomial of degree $(n-1)$, we need to find a set $X$ of \u0026#39;n\u0026#39;. From the previous section, we see that we can write a polynomial in terms of its odd and even coefficients evaluated at $x^2$. For our divide and conquer to work effectively, we need new set $Z = \\{ x^2 | x \\in X \\} $ to be smaller than X. So, how do we arrive at a set of n points such that everytime we square it, we get a smaller set. (I am using the term square loosely here, I mean the set we get by squaring each element in our current set)\nIt turns out we can *always come up with a set of n points, such that they collapse into a set of n/2 points when squared, using complex numbers (Yes, n has to be even)\nIf you don\u0026#39;t quite have an intuitive idea of what complex numbers are, I highly recommend this post on betterexplained by Kalid. For me, the big takeaway about complex numbers was to think about them as rotations. Do read that post.\nComplex numbers are just rotations.\nLet\u0026#39;s start with a set $S_1 = \\{ 1 \\}$. What set can collapse into this set?\nEasy, $S_2 = \\{-1, 1\\}$. What set collapses to $S_2$?\nEasy, $S_3 = \\{i, -i, 1, -1\\}$. What set collapses to $S_3$?\nNot so easy (until you read Kalid\u0026#39;s post!), but it\u0026#39;s $S_4 = \\{\\frac{\\sqrt{2}}{2}(1 + i), -\\frac{\\sqrt{2}}{2}(i + i), \\frac{\\sqrt{2}}{2}(i - 1), -\\frac{\\sqrt{2}}{2}(i + 1), i, -i, 1, -1\\}$.\nWe can keep going. In essence, we can always find a set that collapses like this, for any even n, however big! Take a minute, that is like wow!\nFormally, a set containing $n$ points that collapse as shown above, are called the nth roots of unity. If we square these $n$ points, n times, we get 1 (The basecase of our recursion)!\nRunning time of our Divide and Conquer Algorithm Ok, let\u0026#39;s just step back and see how well our divide and conquer algorithm would perform.\nWe take our polynomial $A(x)$, to be evaluated on a set $X$ with $|X| = n$, and reduce it to two smaller problems. $A_{even}(x)$ and $A_{odd}(x)$, both evaluated on set $Y = \\{x^2 | x \\in X\\}$ with $|Y| = n/2$. We can write a recurrence relation for the above algorithm as:\n$T(n) = 2T(\\frac{n}{2}) + O(n)$\nwhere $T(n)$ is the running time of our algorithm on an input of size $n$. Solving this, we get a runtime bound of O(n lgn)\nCool! We can now Add, Evaluate and Multiply polynomials in $O(n lg n)$ time!\n*This elegant divide and conquer algorithm, is the FFT algorithm!\nI hope this helps you understand what the FFT is all about. In a future post, we will discuss how its implemented, where the $e^{i\\theta}$ and fourier related terms come in.\nReferences Jeff Erickson Algorithm notes TAMU Klappenecker Algorithms OCW Erik Demaine FFT Blog:The Great FFT Algorithms Blog FFT\n","permalink":"https://subsid.github.io/posts/2018-01-10-the-great-fft/","summary":"If you are in the field of software, you\u0026#39;ve probably wondered at some point: What are the coolest algorithms ever discovered?. As a fun task, I decided to try and understand SIAM\u0026#39;s top 10 algorithms of the 20th century.\nThe Fast Fourier Transform (FFT) algorithm is revolutionary. The applications of FFT touches nearly every area of engineering in some way. The Cooley-Tukey paper rediscovered (It was found in Gauss\u0026#39;s notes for calculations in astronomy!","title":"The Great FFT"},{"content":" Sketch recognition is the automated recognition of hand drawn diagrams. In general, sketch recognition techniques can be classified into three types:\nAppearance based This comes more from the field of computer vision, but is not very useful for varying shapes. It does not take temporal data into account.\nGesture based Most useful for forensic methods, but requires user specific training. Every individual has their own quirks when sketching! Geometric based Models are built based on Geometric constraints. Requires neater sketches, but very flexible. The field is quite fascinating, and methods here can be extended into areas of activity recognition and eye tracking. Dr. Hammond\u0026#39;s SRL Lab has some interesting research in the area.\nSketch Tutor is a sketch based game for learning new symbols. Similar to the old game typing-tutor, the idea is to gamify learning a new language, numerals or set of symbos in general. The prototype version of the game supports learning 1-10 numbers in chinese. The scoring is based on a combination of accuracy and number of attempts.\nThe generalized recognition algorithm is based on the $P algorithm. While the current version of the game supports chinese characters from 1-10, the system can be easily extended to have a training phase, where the generalized learning algorithm can be trained on a new set of symbol. Here is the demo and source code. Do let me know what you think.\nBlog:Sketch Tutor Blog Java Script\n","permalink":"https://subsid.github.io/posts/2017-12-15-sketch-tutor/","summary":"Sketch recognition is the automated recognition of hand drawn diagrams. In general, sketch recognition techniques can be classified into three types:\nAppearance based This comes more from the field of computer vision, but is not very useful for varying shapes. It does not take temporal data into account.\nGesture based Most useful for forensic methods, but requires user specific training. Every individual has their own quirks when sketching! Geometric based Models are built based on Geometric constraints.","title":"Sketch Tutor - Game based learning"},{"content":" As a part my of physics based modelling course, I implemented a flocking simulation using threejs.\nFlocking (or Swarming) is a nice example of something known as emergent behavior (wiki).\nEmergence is a phenomenon whereby larger entities arise through interactions among smaller or simpler entities such that the larger entities exhibit properties the smaller/simpler entities do not exhibit.\nThis behavior is common among various animal groups such as birds, ants, bees, fishes. Here is a nice video of starlings flocking around.\nThe idea was popularized in the field of graphics by Craig Reynolds, when he created the famous Boids artificial life simulation in 1986.\nAt its core, each Boid (Bird-oid object!) follows three simple rules:\nSeperation Avoid crowding local buddies. Alignment Direction of velocity should be along the average direction of local buddies. Cohesion Stay centered between local buddies. And that\u0026#39;s it! This leads to some cool emergent behavior. This can be extended in many ways, by adding some obstacle avoidance, common goal and other effects. Something I find really cool is that we can start each boid at some random initial velocity, and see them slowly come together into a nice flock.\nThe source code is available here, in case someone wants to play with it. The implementation is based on this one by Ellie.\nBlog:Physics of flocking Blog Programming Languages Java Script\n","permalink":"https://subsid.github.io/posts/2017-09-22-physics-of-flocking/","summary":"As a part my of physics based modelling course, I implemented a flocking simulation using threejs.\nFlocking (or Swarming) is a nice example of something known as emergent behavior (wiki).\nEmergence is a phenomenon whereby larger entities arise through interactions among smaller or simpler entities such that the larger entities exhibit properties the smaller/simpler entities do not exhibit.\nThis behavior is common among various animal groups such as birds, ants, bees, fishes.","title":"Physics of Flocking"},{"content":" I\u0026#39;ve wanted to start a blog for a while, but it never made it to the top of my queue. After coming back to school, finally got around to start one. Hopefully I can keep it going. Looking forward to writing something more interesting in the future.\nInspired by Kyle\u0026#39;s post, I hope to share some of my work here.\nBlog:First Post Blog\n","permalink":"https://subsid.github.io/posts/2017-07-01-hello-world/","summary":"I\u0026#39;ve wanted to start a blog for a while, but it never made it to the top of my queue. After coming back to school, finally got around to start one. Hopefully I can keep it going. Looking forward to writing something more interesting in the future.\nInspired by Kyle\u0026#39;s post, I hope to share some of my work here.\nBlog:First Post Blog","title":"First Post!"},{"content":" Hi! My name is Siddharth Subramaniyam. Currently focused on building Neural Models at Etsy. My interests broadly fall into Information Retrieval, Distributed Systems, Machine Learning, and Bioinformatics. In the past I\u0026#39;ve worked as a full-stack engineer, SRE, and ML researcher.\nIn Grad school, I was really fascinated by Bioinformatics. With fast and cheap DNA sequencing, we\u0026#39;ve slowly been able to understand the incredible diversity of bacteria. At the Ioerger Lab, I helped build computational tools (like Transit) for statistical analysis of this data in order to learn more about these incredible beings.\nIf any of these interest you, say hi! Twitter | LinkedIn\n","permalink":"https://subsid.github.io/about/","summary":"Hi! My name is Siddharth Subramaniyam. Currently focused on building Neural Models at Etsy. My interests broadly fall into Information Retrieval, Distributed Systems, Machine Learning, and Bioinformatics. In the past I\u0026#39;ve worked as a full-stack engineer, SRE, and ML researcher.\nIn Grad school, I was really fascinated by Bioinformatics. With fast and cheap DNA sequencing, we\u0026#39;ve slowly been able to understand the incredible diversity of bacteria. At the Ioerger Lab, I helped build computational tools (like Transit) for statistical analysis of this data in order to learn more about these incredible beings.","title":"About"}]